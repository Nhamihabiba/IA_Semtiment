# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13eakS3mJBfgdoHeCboy6vuT7dPJU0AjR
"""

import xml.etree.ElementTree as ET
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from sklearn.preprocessing import LabelEncoder

# Téléchargement des ressources NLTK nécessaires
nltk.download('punkt')
nltk.download('stopwords')

def charger_donnees_xml(chemin_fichier):
    """Charge les données depuis un fichier XML et extrait les phrases avec les aspects et polarités."""
    arbre = ET.parse(chemin_fichier)
    racine = arbre.getroot()
    data = []
    for sentence in racine.findall('.//sentence'):
        text = sentence.find('text').text
        aspect_terms = sentence.find('aspectTerms')
        if aspect_terms:
            for aspectTerm in aspect_terms.findall('aspectTerm'):
                data.append((text, aspectTerm.get('term'), aspectTerm.get('polarity')))
    return data

def pretraiter_texte(texte):
    """Nettoie le texte en retirant les stopwords et en le tokenisant."""
    tokens = word_tokenize(texte.lower())
    mots_arret = set(stopwords.words('english'))
    return " ".join([mot for mot in tokens if mot not in mots_arret])

def prepare_data(data):
    """Prépare les données textuelles pour la vectorisation et encode les labels."""
    texts = [pretraiter_texte(text) for text, _, _ in data]
    labels = [polarity for _, _, polarity in data]
    return texts, labels

def vectorize_data(texts):
    """Vectorise les textes prétraités."""
    vectorizer = TfidfVectorizer(stop_words='english')
    return vectorizer.fit_transform(texts), vectorizer

def train_and_evaluate(X_train, y_train, X_test, y_test):
    """Entraîne un modèle d'arbre de décision et évalue sa précision."""
    model = DecisionTreeClassifier(max_depth=5)
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    print(f'Accuracy of the model: {accuracy:.2f}')
    return model

# Charger les données
train_data = charger_donnees_xml('Restaurants_Train.xml') + charger_donnees_xml('Laptop_Train.xml')
test_data = charger_donnees_xml('Restaurants_Test_Gold.xml') + charger_donnees_xml('Laptop_Test_Gold.xml')

# Préparer les données
train_texts, train_labels = prepare_data(train_data)
test_texts, test_labels = prepare_data(test_data)

# Vectorisation des textes
X_train, vectorizer = vectorize_data(train_texts)
X_test = vectorizer.transform(test_texts)

# Encodage des labels
encoder = LabelEncoder()
y_train = encoder.fit_transform(train_labels)
y_test = encoder.transform(test_labels)

# Entraînement et évaluation du modèle
model = train_and_evaluate(X_train, y_train, X_test, y_test)